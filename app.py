import streamlit as st
import face_recognition
import numpy as np
from PIL import Image, ImageDraw

# =========================
# CONFIG
# =========================
st.set_page_config(page_title="Face Recognition App", layout="centered")
st.title("üë§ Nh·∫≠n di·ªán khu√¥n m·∫∑t + ƒê·∫∑t t√™n")

# =========================
# SESSION STORAGE
# =========================
if "known_faces" not in st.session_state:
    st.session_state.known_faces = []  # list of dicts

# =========================
# FUNCTIONS
# =========================
def encode_face(image_np):
    locations = face_recognition.face_locations(image_np)
    if len(locations) != 1:
        return None, None
    encoding = face_recognition.face_encodings(image_np, locations)[0]
    return encoding, locations[0]

# =========================
# TABS
# =========================
tab1, tab2 = st.tabs(["‚ûï ƒêƒÉng k√Ω khu√¥n m·∫∑t", "üîç Nh·∫≠n di·ªán"])

# =========================
# TAB 1 ‚Äì REGISTER
# =========================
with tab1:
    st.subheader("‚ûï ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi")

    name = st.text_input("T√™n ng∆∞·ªùi d√πng")
    img = st.camera_input("Ch·ª•p ·∫£nh khu√¥n m·∫∑t")

    if st.button("üíæ L∆∞u khu√¥n m·∫∑t"):
        if not name or img is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p t√™n v√† ch·ª•p ·∫£nh")
            st.stop()

        image = Image.open(img).convert("RGB")
        img_np = np.array(image)

        encoding, location = encode_face(img_np)

        if encoding is None:
            st.error("‚ùå ·∫¢nh ph·∫£i c√≥ ƒë√∫ng 1 khu√¥n m·∫∑t")
        else:
            st.session_state.known_faces.append({
                "name": name,
                "encoding": encoding
            })
            st.success(f"‚úÖ ƒê√£ l∆∞u khu√¥n m·∫∑t c·ªßa {name}")

# =========================
# TAB 2 ‚Äì RECOGNITION
# =========================
with tab2:
    st.subheader("üîç Nh·∫≠n di·ªán khu√¥n m·∫∑t")

    if len(st.session_state.known_faces) == 0:
        st.info("‚ÑπÔ∏è Ch∆∞a c√≥ khu√¥n m·∫∑t n√†o ƒë∆∞·ª£c ƒëƒÉng k√Ω")
        st.stop()

    img = st.camera_input("Ch·ª•p ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán", key="recognize")

    if img:
        image = Image.open(img).convert("RGB")
        img_np = np.array(image)

        with st.spinner("üß† ƒêang nh·∫≠n di·ªán..."):
            face_locations = face_recognition.face_locations(img_np)
            face_encodings = face_recognition.face_encodings(img_np, face_locations)

        draw = ImageDraw.Draw(image)

        known_encodings = [f["encoding"] for f in st.session_state.known_faces]
        known_names = [f["name"] for f in st.session_state.known_faces]

        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
            matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=0.45)
            name = "Unknown"

            if True in matches:
                name = known_names[matches.index(True)]

            draw.rectangle(((left, top), (right, bottom)), outline="red", width=3)
            draw.text((left, top - 10), name, fill="red")

        st.image(image, caption="K·∫øt qu·∫£ nh·∫≠n di·ªán", use_container_width=True)
